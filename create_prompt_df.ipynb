{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_prompt import (\n",
    "    generate_commentary_translation_prompt,\n",
    "    generate_combined_commentary_prompt,\n",
    "    generate_plain_translation_prompt,\n",
    "    generate_sanskrit_translation_prompt,\n",
    "    generate_standardized_translation_prompt,\n",
    "    generate_word_by_word_translation_prompt\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Map content types to respective prompt functions\n",
    "prompt_functions = {\n",
    "    \"4 commentary translation english\": generate_commentary_translation_prompt,\n",
    "    \"combined commentary english\": generate_combined_commentary_prompt,\n",
    "    \"plain english\": generate_plain_translation_prompt,\n",
    "    \"sanskrit translation\": generate_sanskrit_translation_prompt,\n",
    "    \"standardised translation\": generate_standardized_translation_prompt,\n",
    "    \"word by word translation\": generate_word_by_word_translation_prompt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Default target language\n",
    "DEFAULT_TARGET_LANGUAGE = \"English\"\n",
    "\n",
    "def build_prompt(row, target_language=DEFAULT_TARGET_LANGUAGE):\n",
    "    \"\"\"\n",
    "    Calls the appropriate prompt generator function based on content type.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing content.\n",
    "        target_language (str): The target language for translation (default: \"English\").\n",
    "\n",
    "    Returns:\n",
    "        str: The generated prompt.\n",
    "    \"\"\"\n",
    "    content_type = row.get(\"content type\", \"\").strip().lower()  # Normalize case\n",
    "\n",
    "    # Select the appropriate function or default to plain English translation\n",
    "    prompt_function = prompt_functions.get(content_type, generate_plain_translation_prompt)\n",
    "    \n",
    "    # Generate and return the prompt\n",
    "    return prompt_function(row, target_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send API request with retries\n",
    "def run_gemini_task(task_prompt: str, model_name=\"gemini-pro\", max_retries=5, wait_time=5) -> str:\n",
    "    \"\"\"\n",
    "    Sends an API request to Gemini with retry logic.\n",
    "\n",
    "    Args:\n",
    "        task_prompt (str): The input prompt defining the task.\n",
    "        model_name (str): Gemini model to use (default: \"gemini-pro\").\n",
    "        max_retries (int): Maximum retry attempts if API call fails.\n",
    "        wait_time (int): Seconds to wait before retrying.\n",
    "\n",
    "    Returns:\n",
    "        str: The AI-generated response or an error message.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(task_prompt)\n",
    "\n",
    "            if response and response.text:\n",
    "                return response.text  # Successful response\n",
    "            \n",
    "            print(f\"Attempt {retries + 1}: No response received. Retrying...\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retries + 1}: Error - {e}. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "            retries += 1\n",
    "\n",
    "    return \"Error: Maximum retries reached. Unable to get a response from Gemini.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to process the DataFrame in parallel\n",
    "def process_dataframe(df, target_language=\"English\", num_workers=5):\n",
    "    \"\"\"\n",
    "    Processes the DataFrame by sending prompts in parallel using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing source texts and commentaries.\n",
    "        target_language (str): The target language for translation.\n",
    "        num_workers (int): Number of parallel processes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with translation results.\n",
    "    \"\"\"\n",
    "    # Create prompts for each row\n",
    "    df[\"Prompt\"] = df.apply(lambda row: build_prompt(row, target_language), axis=1)\n",
    "\n",
    "    \n",
    "    # Use multiprocessing for parallel API requests\n",
    "    with multiprocessing.Pool(num_workers) as pool:\n",
    "        results = list(tqdm(pool.imap(run_gemini_task, df[\"Prompt\"]), total=len(df), desc=\"Processing Rows\"))\n",
    "\n",
    "    # Store results in DataFrame\n",
    "    df[\"Translated Text\"] = results\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"buddhist_text_translation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run batch translation\n",
    "translated_df = process_dataframe(df, target_language=\"English\", num_workers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
