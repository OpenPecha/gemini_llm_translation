{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangagyatso/Desktop/work/gemini_llm_translation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import time\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "source_text = \"\"\"ཇི་ལྟར་མཐོང་ཐོས་ཤེས་པ་དག །\n",
    "འདིར་ནི་དགག་པར་བྱ་མིན་ཏེ། །\n",
    "འདིར་ནི་སྡུག་བསྔལ་རྒྱུར་གྱུར་པ། །\n",
    "བདེན་པར་རྟོག་པ་བཟློག་བྱ་ཡིན། །\"\"\"\n",
    "\n",
    "commentaries = [\n",
    "    \"ཇི་ལྟར་མཐོང་ཐོས་དང་ཤེས་པ་འདི་དག་མ་བརྟག་ཉམ་དགའ་ཙམ་གྱི་དབང་དུ་བྱས་ཏེ་བརྗོད་ན་ནི།འདིར་ནི་དགག་པར་བྱ་བ་མིན་ཏེ་དེ་དག་དགག་མི་ནུས་ལ་དགག་ཀྱང་མི་དགོས་པའི་ཕྱིར། འོ་ན་ཅི་ཞིག་འགོག་ཅེ་ན། འདིར་ནི་སྔུག་བསྔལ་གྱི་རྒྱུར་གྱུར་པ་དངོས་པོ་ཀུན་ལ་དེར་ཞེན་གྱི་བདེན་པར་རྟོག་པ་བཟློག་བྱ་ཡིན་ནོ། །འདིར་མཐོང་བ་མངོན་སུམ་དང༌། ཐོས་པ་གང་ཟག་གཞན་ལས་དང༌། ཤེས་པ་རྗེས་དཔག་ཚད་མའི་སྒོ་ནས་བཞག་པའི་ཐ་སྙད་ལ་འགྲེལ་ བས་བཤད་དོ། །\",\n",
    "    \"འདི་ལྟར་ཞེས་བྱ་བ་ལ་སོགས་པ་སྨོས་ཏེ། མཐོང་བ་དང་ཐོས་པ་ལ་སོགས་པ་ཀུན་རྫོབ་ནི་འདིར་མི་འགོག་པའི་ཕྱིར་དང་། འོ་ན་འདིར་ཅི་ཞིག་འགོག་སྙམ་པ་ལ། འདིར་ནི་ཞེས་བྱ་བ་ལ་སོགས་པ་སྨོས་ཏེ། འདི་ནི་སྡུག་བསྔལ་ཐམས་ཅད་འབྱུང་བའི་རྒྱུ་དངོས་པོར་ཞེན་པ་དགག་པའི་ཕྱིར། ཡང་དག་པའི་རང་བཞིན་འགོག་གོ་སྙམ་དུ་བསམས་པའོ།\",\n",
    "    \"གལ་ཏེ་དེ་ལྟར་ན་ཡང་ཤེས་པ་རིག་པ་མེད་ན་དེ་ཇི་ལྟར་མཐོང་ངོ་འདི་ཐོས་སོ་འདི་ཤེས་སོ་ཞེས་བྱ་བའི་ཐ་སྙད་དུ་འགྱུར་རོ་ཞེ་ན། ཇི་ལྟར་ཞེས་བྱ་བ་ལ་སོགས་པ་གསུངས་སོ། ། མཐོང་བ་ལ་སོགས་པའི་ཐ་སྙད་དག་འཇིག་རྟེན་འདིར་དགག་པར་བྱ་བ་མ་ཡིན་པ་དེ་ཁོ་ནའོ། ། འོན་ཀྱང་འདིར་ནི་འཁོར་བའི་སྡུག་བསྔལ་མ་ལུས་པའི་རྒྱུར་འགྱུར་བའི་དངོས་པོར་ཀུན་རྟོག་པ་ནི་གདོན་ཆེན་པོས་བདེན་པ་ཉིད་དུ་སྒྲོ་བཏགས་པ་བྱས་པ་གང་ཡིན་པ་དེ་དགག་པར་བྱ་བ་ཡིན་པས་སྐྱོན་མེད་དོ། ། གཞན་ཡང་ཁྱོད་ཀྱིས་ཇི་སྐད་དུ། གལ་ཏེ་འཁྲུལ་པ་ཡང་མེད་ན། ། ཞེས་བྱ་བ་ལ་སོགས་པ་བརྗོད་པ་དེ་ལ་ཡང་བརྗོད་པར་བྱ་སྟེ།\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import source_translation_prompt\n",
    "\n",
    "prompt = source_translation_prompt(source_text=source_text, commentaries=commentaries, target_language=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following Tibetan text into English.\n",
      "Use the provided commentaries as reference for accurate meaning and interpretation.\n",
      "Each commentary explains the same source text but is written in different languages.\n",
      "Do not merge them; instead, consider all perspectives before providing the translation.\n",
      "\n",
      "### Tibetan Source Text:\n",
      "ཇི་ལྟར་མཐོང་ཐོས་ཤེས་པ་དག །\n",
      "འདིར་ནི་དགག་པར་བྱ་མིན་ཏེ། །\n",
      "འདིར་ནི་སྡུག་བསྔལ་རྒྱུར་གྱུར་པ། །\n",
      "བདེན་པར་རྟོག་པ་བཟློག་བྱ་ཡིན། །\n",
      "\n",
      "### Commentaries:\n",
      "\n",
      "[Commentary 1]:\n",
      "ཇི་ལྟར་མཐོང་ཐོས་དང་ཤེས་པ་འདི་དག་མ་བརྟག་ཉམ་དགའ་ཙམ་གྱི་དབང་དུ་བྱས་ཏེ་བརྗོད་ན་ནི།འདིར་ནི་དགག་པར་བྱ་བ་མིན་ཏེ་དེ་དག་དགག་མི་ནུས་ལ་དགག་ཀྱང་མི་དགོས་པའི་ཕྱིར། འོ་ན་ཅི་ཞིག་འགོག་ཅེ་ན། འདིར་ནི་སྔུག་བསྔལ་གྱི་རྒྱུར་གྱུར་པ་དངོས་པོ་ཀུན་ལ་དེར་ཞེན་གྱི་བདེན་པར་རྟོག་པ་བཟློག་བྱ་ཡིན་ནོ། །འདིར་མཐོང་བ་མངོན་སུམ་དང༌། ཐོས་པ་གང་ཟག་གཞན་ལས་དང༌། ཤེས་པ་རྗེས་དཔག་ཚད་མའི་སྒོ་ནས་བཞག་པའི་ཐ་སྙད་ལ་འགྲེལ་ བས་བཤད་དོ། །\n",
      "\n",
      "[Commentary 2]:\n",
      "འདི་ལྟར་ཞེས་བྱ་བ་ལ་སོགས་པ་སྨོས་ཏེ། མཐོང་བ་དང་ཐོས་པ་ལ་སོགས་པ་ཀུན་རྫོབ་ནི་འདིར་མི་འགོག་པའི་ཕྱིར་དང་། འོ་ན་འདིར་ཅི་ཞིག་འགོག་སྙམ་པ་ལ། འདིར་ནི་ཞེས་བྱ་བ་ལ་སོགས་པ་སྨོས་ཏེ། འདི་ནི་སྡུག་བསྔལ་ཐམས་ཅད་འབྱུང་བའི་རྒྱུ་དངོས་པོར་ཞེན་པ་དགག་པའི་ཕྱིར། ཡང་དག་པའི་རང་བཞིན་འགོག་གོ་སྙམ་དུ་བསམས་པའོ།\n",
      "\n",
      "[Commentary 3]:\n",
      "གལ་ཏེ་དེ་ལྟར་ན་ཡང་ཤེས་པ་རིག་པ་མེད་ན་དེ་ཇི་ལྟར་མཐོང་ངོ་འདི་ཐོས་སོ་འདི་ཤེས་སོ་ཞེས་བྱ་བའི་ཐ་སྙད་དུ་འགྱུར་རོ་ཞེ་ན། ཇི་ལྟར་ཞེས་བྱ་བ་ལ་སོགས་པ་གསུངས་སོ། ། མཐོང་བ་ལ་སོགས་པའི་ཐ་སྙད་དག་འཇིག་རྟེན་འདིར་དགག་པར་བྱ་བ་མ་ཡིན་པ་དེ་ཁོ་ནའོ། ། འོན་ཀྱང་འདིར་ནི་འཁོར་བའི་སྡུག་བསྔལ་མ་ལུས་པའི་རྒྱུར་འགྱུར་བའི་དངོས་པོར་ཀུན་རྟོག་པ་ནི་གདོན་ཆེན་པོས་བདེན་པ་ཉིད་དུ་སྒྲོ་བཏགས་པ་བྱས་པ་གང་ཡིན་པ་དེ་དགག་པར་བྱ་བ་ཡིན་པས་སྐྱོན་མེད་དོ། ། གཞན་ཡང་ཁྱོད་ཀྱིས་ཇི་སྐད་དུ། གལ་ཏེ་འཁྲུལ་པ་ཡང་མེད་ན། ། ཞེས་བྱ་བ་ལ་སོགས་པ་བརྗོད་པ་དེ་ལ་ཡང་བརྗོད་པར་བྱ་སྟེ།\n",
      "\n",
      "### Expected Output:\n",
      "Provide a English translation of the source text by incorporating relevant insights from all the commentaries.\n",
      "Ensure the meaning is accurately conveyed, considering different interpretations where necessary.\n",
      "I need the translation of source text only.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_gemini_task(task_prompt: str, model_name=\"gemini-pro\", max_retries=5, wait_time=5) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response from Gemini based on the given prompt, with retry logic for robustness.\n",
    "\n",
    "    Args:\n",
    "        task_prompt (str): The input prompt defining the task.\n",
    "        model_name (str): Gemini model to use (default: \"gemini-pro\").\n",
    "        max_retries (int): Maximum number of retry attempts if the API call fails (default: 5).\n",
    "        wait_time (int): Number of seconds to wait before retrying (default: 5).\n",
    "\n",
    "    Returns:\n",
    "        str: The AI-generated response or an error message after max retries.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(task_prompt)\n",
    "\n",
    "            if response and response.text:\n",
    "                return response.text  # Successful response\n",
    "            \n",
    "            print(f\"Attempt {retries + 1}: No response received. Retrying...\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retries + 1}: Error encountered - {e}. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "            retries += 1\n",
    "\n",
    "    return \"Error: Maximum retries reached. Unable to get a response from Gemini.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whatever is seen, heard, or thought is not denied in these lines; rather, the reality that is conceived as the cause of suffering is denied here.\n"
     ]
    }
   ],
   "source": [
    "translated_text = run_gemini_task(task_prompt=prompt, model_name=\"gemini-pro\")\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the output file name\n",
    "output_file = \"translated.txt\"\n",
    "\n",
    "# Write the text to the file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(translated_text)\n",
    "\n",
    "print(f\"Text successfully written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "def save_translation_to_jsonl(tibetan_text, translated_text, output_file=\"translations.jsonl\", content_type=\"scripture_translation\", target_language=\"english\"):\n",
    "    \"\"\"\n",
    "    Saves the Tibetan source text and translated text as a list of tuples in a JSONL file.\n",
    "\n",
    "    Args:\n",
    "        tibetan_text (str): Original Tibetan text.\n",
    "        translated_text (str): Translated text.\n",
    "        output_file (str): JSONL file name (default: \"translations.jsonl\").\n",
    "        content_type (str): The type/category of the translation (default: \"scripture_translation\").\n",
    "        target_language (str): Target language name (default: \"english\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare JSONL entry as a list of tuples\n",
    "    entry = [\n",
    "        (tibetan_text.strip(), translated_text.strip(), content_type)\n",
    "    ]\n",
    "\n",
    "    # Write to JSONL file\n",
    "    with jsonlines.open(output_file, mode='a') as writer:\n",
    "        writer.write(entry)\n",
    "\n",
    "    print(f\"Translation saved successfully in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation saved successfully in translations.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "output_filename = \"translations.jsonl\"\n",
    "save_translation_to_jsonl(\n",
    "    source_text,\n",
    "    translated_text,\n",
    "    output_file=output_filename,\n",
    "    content_type=\"Plain English\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
